{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794efa91",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure OpenAI LLM\n",
    "Initialize and connect to the Azure OpenAI service using credentials from environment variables to enable chat completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7af7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to llm\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(   \n",
    "  model=\"gpt-4o\",#  Replace with your actual deployment name from Azure Portal\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"This is a test.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61699508",
   "metadata": {},
   "source": [
    "## 2. Install Azure Search Documents Library\n",
    "Install the required `azure-search-documents` package to interact with Azure AI Search service.\n",
    "- pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005acdd",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure AI Search Service\n",
    "Initialize the SearchClient with endpoint, index name, and API key from environment variables to enable queries against the Azure Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea22752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
    "key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b98dd",
   "metadata": {},
   "source": [
    "## 4. Search and Display Results\n",
    "Execute a search query against the Azure Search index and display all results with their fields and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Semantic search with reranking\n",
    "results = search_client.search(\n",
    "    search_text=\"ROBERT AUDI\",\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",  # or your configured semantic config name\n",
    "    top=5  # number of results to return\n",
    ")\n",
    "\n",
    "print(\"Semantic Search Results...\")\n",
    "result_list = list(results)\n",
    "print(f\"Number of results: {len(result_list)}\")\n",
    "\n",
    "if result_list:\n",
    "    print(\"\\nFirst result:\")\n",
    "    print(result_list[0])\n",
    "    \n",
    "    for i, result in enumerate(result_list):\n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        for key, value in result.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af957d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dd9a841",
   "metadata": {},
   "source": [
    "## 8. Compare Normal Search vs Semantic Search\n",
    "\n",
    "### What You'll See\n",
    "\n",
    "This cell performs **both search types** on the same query and compares the results:\n",
    "\n",
    "- **üîµ Normal Keyword Search**: Matches exact words in your documents\n",
    "- **üü¢ Semantic Search**: Understands meaning and context, ranks by relevance\n",
    "\n",
    "### Which One is Better?\n",
    "\n",
    "It depends on your use case:\n",
    "- **Normal Search**: Fast, good for exact matches (\"John Smith\")\n",
    "- **Semantic Search**: Smarter, better at understanding intent (\"Who is the main character?\")\n",
    "\n",
    "**For RAG applications**: Semantic Search usually gives better results because it understands meaning, not just keywords.\n",
    "\n",
    "### Try It!\n",
    "\n",
    "Enter a search query below and compare the results from both search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Define which fields you want to display\n",
    "# those fields and data just for test that's why the ain't that good \n",
    "IMPORTANT_FIELDS = [\n",
    "    'metadata_storage_name',      # File name\n",
    "    'content',                     # Main content\n",
    "    'keyphrases',                  # Key phrases\n",
    "    'people',                       # People mentioned\n",
    "]\n",
    "\n",
    "user_query = input(\"What do you want to search for? = \")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"QUERY: {user_query}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. NORMAL (KEYWORD) SEARCH\n",
    "# ============================================================================\n",
    "print(\"üîµ NORMAL KEYWORD SEARCH\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "normal_results = search_client.search(search_text=user_query, top=5)\n",
    "normal_list = list(normal_results)\n",
    "\n",
    "print(f\"Results found: {len(normal_list)}\\n\")\n",
    "\n",
    "if normal_list:\n",
    "    for i, result in enumerate(normal_list, 1):\n",
    "        print(f\"  Result {i}:\")\n",
    "        for key, value in result.items():\n",
    "            # Only show important fields\n",
    "            if key in IMPORTANT_FIELDS:\n",
    "                # Truncate long values for readability\n",
    "                if isinstance(value, str):\n",
    "                    value_str = value[:150] + \"...\" if len(value) > 150 else value\n",
    "                else:\n",
    "                    value_str = str(value)[:150] + \"...\" if len(str(value)) > 150 else str(value)\n",
    "                print(f\"    {key}: {value_str}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No results found.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SEMANTIC SEARCH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üü¢ SEMANTIC SEARCH (AI-Powered Ranking)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "semantic_results = search_client.search(\n",
    "    search_text=user_query,\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",\n",
    "    top=5\n",
    ")\n",
    "\n",
    "semantic_list = list(semantic_results)\n",
    "\n",
    "print(f\"Results found: {len(semantic_list)}\\n\")\n",
    "\n",
    "if semantic_list:\n",
    "    for i, result in enumerate(semantic_list, 1):\n",
    "        print(f\"  Result {i}:\")\n",
    "        for key, value in result.items():\n",
    "            # Only show important fields\n",
    "            if key in IMPORTANT_FIELDS:\n",
    "                # Truncate long values for readability\n",
    "                if isinstance(value, str):\n",
    "                    value_str = value[:150] + \"...\" if len(value) > 150 else value\n",
    "                else:\n",
    "                    value_str = str(value)[:150] + \"...\" if len(str(value)) > 150 else str(value)\n",
    "                print(f\"    {key}: {value_str}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No results found.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Normal Search Results:    {len(normal_list)} documents\")\n",
    "print(f\"Semantic Search Results:  {len(semantic_list)} documents\")\n",
    "print(\"\\nüí° Note:\")\n",
    "print(\"  - Normal Search: Matches keywords in documents\")\n",
    "print(\"  - Semantic Search: Understands meaning and context better\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c564ad",
   "metadata": {},
   "source": [
    "# single turn-chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87aac96",
   "metadata": {},
   "source": [
    "## Query Rewriting for Better Search Results\n",
    "\n",
    "Before searching, we optimize the user's natural language question into a search-optimized query. This helps Azure AI Search find more relevant philosophy documents by:\n",
    "- Extracting key philosophical terms and concepts\n",
    "- Removing conversational filler words\n",
    "- Expanding with related philosophical terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message for query rewriting - optimized for philosophy searches\n",
    "QUERY_REWRITE_SYSTEM_MESSAGE = \"\"\"You are a query optimization assistant for a philosophy knowledge base (Cambridge Dictionary of Philosophy).\n",
    "\n",
    "Your task: Transform the user's natural language question into an optimized search query for Azure AI Search.\n",
    "\n",
    "Rules:\n",
    "1. Extract key philosophical terms, concepts, and philosopher names\n",
    "2. Remove conversational words (what, how, can you, please, etc.)\n",
    "3. Include relevant philosophical synonyms or related terms\n",
    "4. Keep it concise (3-10 words maximum)\n",
    "5. Return ONLY the optimized query - no explanations, no quotes, no extra text\n",
    "\n",
    "Examples:\n",
    "- User: \"What did Kant think about morality?\" ‚Üí \"Kant ethics moral philosophy categorical imperative\"\n",
    "- User: \"Can you explain what existentialism means?\" ‚Üí \"existentialism Sartre Heidegger existence meaning\"\n",
    "- User: \"Who is Plato and what are his main ideas?\" ‚Üí \"Plato forms idealism Republic Socrates\"\n",
    "- User: \"What's the difference between ethics and morality?\" ‚Üí \"ethics morality moral philosophy normative\"\n",
    "- User: \"Tell me about free will\" ‚Üí \"free will determinism libertarianism compatibilism\"\n",
    "\n",
    "Remember: Output ONLY the optimized search query, nothing else.\"\"\"\n",
    "\n",
    "\n",
    "def rewrite_query(user_message: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a user's natural language question and returns an optimized search query.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": QUERY_REWRITE_SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        max_tokens=50,  # Keep responses short\n",
    "        temperature=0.3  # Lower temperature for more consistent outputs\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a10826",
   "metadata": {},
   "source": [
    "# test the query llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the query rewriter\n",
    "test_questions = [\n",
    "    \"What is the meaning of life according to philosophers?\",\n",
    "    \"Can you explain Nietzsche's ideas?\",\n",
    "    \"What's epistemology about?\"\n",
    "]\n",
    "\n",
    "print(\"üîÑ Query Rewriting Examples:\\n\")\n",
    "for q in test_questions:\n",
    "    optimized = rewrite_query(q)\n",
    "    print(f\"Original:  {q}\")\n",
    "    print(f\"Optimized: {optimized}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71571408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full RAG pipeline with query rewriting\n",
    "\n",
    "user_message = input(\"Ask a philosophy question: \")\n",
    "\n",
    "# Step 1: Rewrite the query for better search\n",
    "print(f\"\\nüìù Original question: {user_message}\")\n",
    "optimized_query = rewrite_query(user_message)\n",
    "print(f\"üîÑ Optimized query: {optimized_query}\")\n",
    "\n",
    "# Step 2: Search with the optimized query\n",
    "semantic_results = search_client.search(\n",
    "    search_text=optimized_query,  # Use optimized query instead of raw user input\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",\n",
    "    select=[ \"keyphrases\"],  # Exclude 'content'\n",
    "    top=2\n",
    ")\n",
    "semantic_list = list(semantic_results)\n",
    "print(f\" üìö Found {len(semantic_list)} relevant documents\")\n",
    "#okay we will be using the semantic search for the rag \n",
    "#here we will just retrive then pass directly to the agent to reformulate the answer and its gonna be single-turn chat \n",
    "# then we will do muilt-turn-chat and see the result with query rewriting \n",
    "#The top=1 parameter specifies how many search results you want returned from Azure AI Search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For RAG applications, you typically want to retrieve multiple relevant documents (not just 1) to give the LLM more context. Common values are:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ed713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For RAG applications, you should convert the search results to a string before passing them to the LLM. Here's why and how:\n",
    "\n",
    "Why String Format?\n",
    "LLMs work with text input, not Python objects\n",
    "You need to structure the context in a readable format\n",
    "You want to include only relevant fields (not all metadata)\n",
    "\n",
    "\"\"\"\n",
    "#i think of using MS markitdown \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(results):## turn the search to markdown \n",
    "    if not results:\n",
    "        return \"No relevant documents found.\"\n",
    "    blocks = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        blocks.append(\n",
    "            f\"### Document {i}\\n\"\n",
    "            f\"- **filename:** {doc.get('metadata_storage_name', 'N/A')}\\n\"\n",
    "            f\"- **people:** {', '.join(doc.get('people', [])) if doc.get('people') else 'N/A'}\\n\"\n",
    "            f\"- **keyphrases:** {', '.join(doc.get('keyphrases', [])) if doc.get('keyphrases') else 'N/A'}\\n\\n\"\n",
    "            f\"**content:**\\n{doc.get('content', 'N/A')}\\n\"\n",
    "        )\n",
    "    return \"\\n---\\n\".join(blocks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust max_content_length based on your needs:\n",
    "# - 2000 chars = ~500 tokens (very concise)\n",
    "# - 4000 chars = ~1000 tokens (good balance)\n",
    "# - 8000 chars = ~2000 tokens (more context)\n",
    "\n",
    "context_md = to_markdown(semantic_list)\n",
    "print(f\"Context length: {len(context_md)} characters (~{len(context_md)//4} tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message= \"\"\" you are going to, revice a result of search from azure ai search index your job is to take that \n",
    "result and reforumlate an answer to the user based on his question \n",
    "\"\"\"\n",
    "print((context_md))\n",
    "#here is another error \n",
    "# i exceeded the rate limit 308373   this is the context you are planing to pass your model to \n",
    "#too much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1db914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to LLM with proper system message and structured prompt\n",
    "\"\"\"About the 429 error: This is a rate limit from Azure OpenAI - you've made too many requests. Just wait 30-60 seconds before running the cell again. This is not a code issue, it's Azure throttling your requests.\"\"\"\n",
    "response = client.chat.completions.create(   \n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": f\"Context:\\n{context_md}\\n\\nQuestion: {user_message}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c27b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
