{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794efa91",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure OpenAI LLM\n",
    "Initialize and connect to the Azure OpenAI service using credentials from environment variables to enable chat completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7af7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to llm\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(   \n",
    "  model=\"gpt-4o\",#  Replace with your actual deployment name from Azure Portal\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"This is a test.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61699508",
   "metadata": {},
   "source": [
    "## 2. Install Azure Search Documents Library\n",
    "Install the required `azure-search-documents` package to interact with Azure AI Search service.\n",
    "- pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005acdd",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure AI Search Service\n",
    "Initialize the SearchClient with endpoint, index name, and API key from environment variables to enable queries against the Azure Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea22752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
    "key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b98dd",
   "metadata": {},
   "source": [
    "## 4. Search and Display Results\n",
    "Execute a search query against the Azure Search index and display all results with their fields and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Semantic search with reranking\n",
    "results = search_client.search(\n",
    "    search_text=\"ROBERT AUDI\",\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",  # or your configured semantic config name\n",
    "    top=5  # number of results to return\n",
    ")\n",
    "\n",
    "print(\"Semantic Search Results...\")\n",
    "result_list = list(results)\n",
    "print(f\"Number of results: {len(result_list)}\")\n",
    "\n",
    "if result_list:\n",
    "    print(\"\\nFirst result:\")\n",
    "    print(result_list[0])\n",
    "    \n",
    "    for i, result in enumerate(result_list):\n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        for key, value in result.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af957d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dd9a841",
   "metadata": {},
   "source": [
    "## 8. Compare Normal Search vs Semantic Search\n",
    "\n",
    "### What You'll See\n",
    "\n",
    "This cell performs **both search types** on the same query and compares the results:\n",
    "\n",
    "- **ðŸ”µ Normal Keyword Search**: Matches exact words in your documents\n",
    "- **ðŸŸ¢ Semantic Search**: Understands meaning and context, ranks by relevance\n",
    "\n",
    "### Which One is Better?\n",
    "\n",
    "It depends on your use case:\n",
    "- **Normal Search**: Fast, good for exact matches (\"John Smith\")\n",
    "- **Semantic Search**: Smarter, better at understanding intent (\"Who is the main character?\")\n",
    "\n",
    "**For RAG applications**: Semantic Search usually gives better results because it understands meaning, not just keywords.\n",
    "\n",
    "### Try It!\n",
    "\n",
    "Enter a search query below and compare the results from both search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Define which fields you want to display\n",
    "# those fields and data just for test that's why the ain't that good \n",
    "IMPORTANT_FIELDS = [\n",
    "    'metadata_storage_name',      # File name\n",
    "    'content',                     # Main content\n",
    "    'keyphrases',                  # Key phrases\n",
    "    'people',                       # People mentioned\n",
    "]\n",
    "\n",
    "user_query = input(\"What do you want to search for? = \")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"QUERY: {user_query}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. NORMAL (KEYWORD) SEARCH\n",
    "# ============================================================================\n",
    "print(\"ðŸ”µ NORMAL KEYWORD SEARCH\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "normal_results = search_client.search(search_text=user_query, top=5)\n",
    "normal_list = list(normal_results)\n",
    "\n",
    "print(f\"Results found: {len(normal_list)}\\n\")\n",
    "\n",
    "if normal_list:\n",
    "    for i, result in enumerate(normal_list, 1):\n",
    "        print(f\"  Result {i}:\")\n",
    "        for key, value in result.items():\n",
    "            # Only show important fields\n",
    "            if key in IMPORTANT_FIELDS:\n",
    "                # Truncate long values for readability\n",
    "                if isinstance(value, str):\n",
    "                    value_str = value[:150] + \"...\" if len(value) > 150 else value\n",
    "                else:\n",
    "                    value_str = str(value)[:150] + \"...\" if len(str(value)) > 150 else str(value)\n",
    "                print(f\"    {key}: {value_str}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No results found.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SEMANTIC SEARCH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŸ¢ SEMANTIC SEARCH (AI-Powered Ranking)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "semantic_results = search_client.search(\n",
    "    search_text=user_query,\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",\n",
    "    top=5\n",
    ")\n",
    "\n",
    "semantic_list = list(semantic_results)\n",
    "\n",
    "print(f\"Results found: {len(semantic_list)}\\n\")\n",
    "\n",
    "if semantic_list:\n",
    "    for i, result in enumerate(semantic_list, 1):\n",
    "        print(f\"  Result {i}:\")\n",
    "        for key, value in result.items():\n",
    "            # Only show important fields\n",
    "            if key in IMPORTANT_FIELDS:\n",
    "                # Truncate long values for readability\n",
    "                if isinstance(value, str):\n",
    "                    value_str = value[:150] + \"...\" if len(value) > 150 else value\n",
    "                else:\n",
    "                    value_str = str(value)[:150] + \"...\" if len(str(value)) > 150 else str(value)\n",
    "                print(f\"    {key}: {value_str}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"  No results found.\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Normal Search Results:    {len(normal_list)} documents\")\n",
    "print(f\"Semantic Search Results:  {len(semantic_list)} documents\")\n",
    "print(\"\\nðŸ’¡ Note:\")\n",
    "print(\"  - Normal Search: Matches keywords in documents\")\n",
    "print(\"  - Semantic Search: Understands meaning and context better\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c564ad",
   "metadata": {},
   "source": [
    "# single turn-chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76278c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay we will be using the semantic search for the rag \n",
    "#here we will just retrive then pass directly to the agent to reformulate the answer and its gonna be single-turn chat \n",
    "# then we will do muilt-turn-chat and see the result with query rewriting  \n",
    "\n",
    "user_message = input(\"write here you message = \")\n",
    "#let's retrive somthing cool \n",
    "semantic_results = search_client.search(\n",
    "    search_text=user_message,\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name=\"default\",\n",
    "    top=1\n",
    ")\n",
    "\n",
    "semantic_list = list(semantic_results)\n",
    "#The top=1 parameter specifies how many search results you want returned from Azure AI Search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For RAG applications, you typically want to retrieve multiple relevant documents (not just 1) to give the LLM more context. Common values are:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ed713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For RAG applications, you should convert the search results to a string before passing them to the LLM. Here's why and how:\n",
    "\n",
    "Why String Format?\n",
    "LLMs work with text input, not Python objects\n",
    "You need to structure the context in a readable format\n",
    "You want to include only relevant fields (not all metadata)\n",
    "\n",
    "\"\"\"\n",
    "#i think of using markitdown \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(results):## turn the search to markdown \n",
    "    if not results:\n",
    "        return \"No relevant documents found.\"\n",
    "    blocks = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        blocks.append(\n",
    "            f\"### Document {i}\\n\"\n",
    "            f\"- **filename:** {doc.get('metadata_storage_name', 'N/A')}\\n\"\n",
    "            f\"- **people:** {', '.join(doc.get('people', [])) if doc.get('people') else 'N/A'}\\n\"\n",
    "            f\"- **keyphrases:** {', '.join(doc.get('keyphrases', [])) if doc.get('keyphrases') else 'N/A'}\\n\\n\"\n",
    "            f\"**content:**\\n{doc.get('content', 'N/A')}\\n\"\n",
    "        )\n",
    "    return \"\\n---\\n\".join(blocks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_md = to_markdown(semantic_list)\n",
    "print(context_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message= \"\"\" you are going to, revice a result of search from azure ai search index your job is to take that \n",
    "result and reforumlate an answer to the user based on his question \n",
    "\"\"\"\n",
    "print((context_md))\n",
    "#here is another error \n",
    "# i exceeded the rate limit 308373   this is the context you are planing to pass your model to \n",
    "#too much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1db914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to LLM with proper system message and structured prompt\n",
    "\"\"\"About the 429 error: This is a rate limit from Azure OpenAI - you've made too many requests. Just wait 30-60 seconds before running the cell again. This is not a code issue, it's Azure throttling your requests.\"\"\"\n",
    "response = client.chat.completions.create(   \n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": f\"Context:\\n{context_md}\\n\\nQuestion: {user_message}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c27b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
